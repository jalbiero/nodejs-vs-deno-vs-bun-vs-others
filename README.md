# NodeJS vs Deno vs Bun vs Others

- [NodeJS vs Deno vs Bun vs Others](#nodejs-vs-deno-vs-bun-vs-others)
  - [Introduction](#introduction)
  - [Tests](#tests)
    - [Description](#description)
    - [Programming languages/Frameworks used](#programming-languagesframeworks-used)
    - [Notes](#notes)
  - [Results](#results)
    - [TODO](#todo)
  - [How to run the tests](#how-to-run-the-tests)
    - [Requirements](#requirements)
    - [Instructions](#instructions)

**DISCLAIMER: this document is a work in progress (tests are finished, but results are to be published together with the instructions to carry on them)**

## Introduction

With the arrival of a new competitor to the Javascript runtime ecosystem, _Bun_, I was curious about how fast it is, because one of its selling points is that it is faster than NodeJS and Deno. 

So, the idea of this repository, is to test the following Javascript runtime environments:

Runtime | Appareance | Coded in | Estimated usage [(*)](https://devclass.com/2023/01/11/javascript-survey-shows-enthusiasm-for-tauri-over-electron-and-vite-over-webpack/)
-- | -- | -- | --
[NodeJS](https://en.wikipedia.org/wiki/Node.js) | 2009 | C++ | 71%
[Deno](https://en.wikipedia.org/wiki/Deno_(software)) | 2018 | Rust (originally in Go) | 8.5%
[Bun](https://bun.sh/) | 2021 | Zig | 3.2%

In order to make the tests more interesting I added 2 fast native environments, C++ and Rust, a classic one like Java (no GraalVM at the moment), and also a "slow" one like Python. Future versions of these tests will include Go and a GraalVM version of the Java test.

## Tests

### Description

1. Tests are based on the following REST APIs:

    Verb | Route | Result | Description
    -- | -- | -- | -- 
    GET | `/` | Fixed little string: e.g. "Deno test" | Very simple API that returns a fixed data
    GET | `/echo/<data>` | Return the same `<data>` | Simple API that returns the same received data
    GET | `/getPrimesLessThan/<limit>` | Returns a list of primes less than `<limit>` | CPU and memory usage are function of the specified _limit_
    GET | `/countPrimesLessThan/<limit>` | Returns the number of primes less than `<limit>` | CPU usage is function of the specified _limit_

2. Tests are executed using [JMeter](https://jmeter.apache.org/) from command line (see [Test Makefile](Makefile)).
   - The [JMeter Test Plan](tests/jmeter/) has the following features:
     1. Each REST API is called from its own Thread Group. All Thread Groups are executed sequentially.
     2. Each Thread Group was configured with (*):
        - 10 threads 
        - 2000 requests per thread  

    (*) See [Test Makefile](Makefile) for more information

### Programming languages/Frameworks used

Language/Runtime | Version (*) | REST Library/Framework | Version 
-- | -- | -- | -- 
Bun  | 0.5.9 | Express | 4.18.2
C++  | g++ 12.2.1, C++20 mode | Drogon | 1.8.4
C#   | 11 | .NET | 7.0
Deno | 1.33.3 | Express | 4.18.2
Java (OpenJDK) | 19.0.1 | Spring boot | 3.0.6
NodeJS | 20.1.0 | Express | 4.18.2
Python | 3.11.3 | Flask | 2.3.2
Rust | 1.69.0 | Rocket | 0.5.0-rc.3

(*) For more information about the latest versions check the [version.txt](apps/versions.txt) file.

All test applications are dockerized in order to be easy to execute/validate them by anyone.

### Notes
- All tests are coded without tweeking them for performance (CPU, network usage, etc) or memory consumption. The idea is to add tweaks for all examples in the future.
- Currently the only minor tweak is in the Rust application in order to be on pair with C++ (primes functions were hinted as _inline_).
- For sure there are better ways to test these runtimes/languages, but as an entry point, they could be useful to have an idea of where is each implementation.
- 

## Results

### TODO


## How to run the tests

### Requirements

- Docker and docker compose
- make
- git

### Instructions

Running the test is very easy, just follow the next steps:

0. Open a terminal, clone the repository and go to the project directory:

    ```bash
    $ git clone git@github.com:jalbiero/nodejs-vs-deno-vs-bun-vs-others.git
    $ cd nodejs-vs-deno-vs-bun-vs-others
    ```

1. Build the docker images for each test application (Right now I don't have plans to upload the images to docker hub, but it is a possibility)

    ```bash
    $ make build
    ```

2. Run tests

    ```bash
    $ make run
    ```

    - Test results are generated by default in `nodejs-vs-deno-vs-bun-vs-others/tests/results`
    - Be aware that previous results will be overwitten